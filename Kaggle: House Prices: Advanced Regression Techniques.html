<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.2.1 (458835)"/><meta name="author" content="18742085220@163.com"/><meta name="created" content="2019-11-18 12:54:51 +0000"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2019-11-24 13:26:26 +0000"/><title>Kaggle: House Prices: Advanced Regression Techniques</title></head><body><div><span style="font-weight: bold; font-size: 24px;">比赛概述
</span></div><div>在本题的数据库中，有79个变量涵盖了住宅的方方面面，根据这些变量条件预测最终的房价。
</div><div><br/></div><div><span style="font-weight: bold; font-size: 24px;">技术使用</span></div><div>特征工程
</div><div>回归模型
</div><div><br/></div><div><span style="font-weight: bold; font-size: 24px;">提交格式
</span></div><div><span style="color: black; font-family: Monaco;">Id,SalePrice</span></div><div><span style="color: black; font-family: Monaco;">1461,169000.1</span></div><div><span style="color: black; font-family: Monaco;">1462,187724.1233</span></div><div><span style="color: black; font-family: Monaco;">1463,175221</span></div><div><span style="color: black; font-family: Monaco;">etc.</span></div><div><span style="color: black; font-family: Monaco;"><br/></span></div><div><font style="font-size: 24px;"><span style="color: rgb(0, 0, 0); font-family: Monaco; --inversion-type-color:  simple; font-size: 24px; font-weight: bold;">数据分析
</span></font></div><div><span style="--inversion-type-color:  simple; color: rgb(0, 0, 0); font-family: Monaco;">数据描述
</span></div><div><span style="--inversion-type-color:  simple; color: rgb(0, 0, 0); font-family: Monaco;">首先导入数据查看：</span></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>df_train = pd.read_csv('train.csv',index_col = 0)</div><div>df_test = pd.read_csv('test.csv',index_col = 0)</div><div>df_train.head()</div></div><div><br/></div><div><span style="--inversion-type-color:  simple; color: rgb(0, 0, 0); font-family: Monaco;"
/></div><div><span style="--inversion-type-color:  simple; color: rgb(0, 0, 0); font-family: Monaco;"><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/0A49E134-5BDA-4A82-8B7E-F79660F63F81.png" height="227" width="1004"/><br/></span></div><div><br/></div><div>数据集总计80列，即总共79个特征。</div><div>接下来需要将训练集和测试集进行合并，这是为了方便进行数据预处理，另外，预测值即SalePrice这一列需单独拿出。</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div><span style="font-size: 12px; font-family: Monaco;">df = pd.concat((df_train,df_test),axis=0)</span></div><div><font face="Monaco">df = df.drop([’SalePrice’],axis=1)</font></div><div><font face="Monaco">df.shape</font></div></div><div><br/></div><div><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/D7F00790-4496-40C4-900B-688EF3F27C7A.png" height="37" width="136"/><br/></div><div>整个数据集2919个样本，共79个特征</div><div><br/></div><div>然后把训练数据集的SalePrice一列单独拿出来</div><div><br/></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>y_train= df_train.pop(’SalePrice’)</div></div><div><br/></div><div>在处理特征之前，还需要观察一下预测值的分布情况，看是否需要进行处理。</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>sns.displot(y_train)</div></div><div><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/9C3CCB26-3802-4018-9C0E-8DD2F8337369.png" height="274" width="429"/><br/></div><div>分布如图所示，再进一步确定曲线的峰度和偏度</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>y_train.kurt()</div></div><div><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/7A58531C-E0A5-4B3A-BA0F-AE2ABC03E0A6.png" height="21" width="162"/><br/></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><span style="font-size: 12px; font-family: Monaco;">y_train.skew()</span></div><div><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/13958F98-5BFA-4A42-B319-327960182F53.png" height="19" width="165"/><br/></div><div><br/></div><div>综上所示，曲线的峰度和偏度都大于0，表示曲线相比于正态分布的高峰更加陡峭，长尾向右拖。为了将预测变量总体平滑化，在这里参考相关的做法，使用的是log(x+1)。</div><div><br/></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>y_train= np.log1p(y_train)</div><div><br/></div><div>y_train.head()</div></div><div><br/></div><div><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/A597EE7E-EF39-417E-8EFF-DCD8A96E3EBA.png" height="126" width="283"/><br/></div><div><br/></div><div>在进行特征工程之前，需要对特征的缺失值有个大致的判断。</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>df.isnull().sum()</div></div><div><br/></div><div><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/Xnip2019-11-18_22-23-38%E7%9A%84%E5%89%AF%E6%9C%AC.jpg" height="1069" width="189"/><br/></div><div>将缺失值最多的前10个变量展示出来：</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>df.isnull().sum().sort_values(ascending=False).head(10)</div></div><div><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/385F7534-3522-4BD0-A91F-0D5188937C8F.png" height="192" width="191"/><br/></div><div><br/></div><div>可以看到有缺失值的变量既有numerical数据，也有category数据，对其的处理将在接下来的特征工程中进行。</div><div>接下来进行特征工程：</div><div>首先对于category数据，可以直接使用pandas中的get_dummies方法，自动将分类数据生成虚拟变量：</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>df_dummy = pd.get_dummies(df)</div><div>df_dummy.head()</div></div><div><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/735C0D8C-FCCA-474A-899F-E1D5BA5D48D7.png" height="219" width="539"/><br/></div><div><br/></div><div>接下来处理numerical数据</div><div>再次查看虚拟变量化之后的数据缺失情况：</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>df_dummy.isnull().sum().sort_values(asacending=False).head(10)</div></div><div><br/></div><div><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/B305A4B2-9CC3-44AA-ADE1-A3174CCFE9B2.png" height="195" width="194"/><br/></div><div><br/></div><div>对于这些缺失的numerical数据，直接使用平均值进行填充，并确定缺失值数量为0。</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>mean_cols = df_dummy.mean()</div><div>df_dummy = df_dummy.fillna(mean_cols)</div><div><br/></div><div>df_dummy.isnull().sum().sum()</div></div><div><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/EB984F38-CB1C-4AC9-8922-AD0576756090.png" height="24" width="82"/><br/></div><div><br/></div><div>另外，对于numerical数据，也需要将数据进行平滑化，即标准化。</div><div>首先需要将numerical数据提出来</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>numerical_cols = df_dummy.columns[df_dummy.dtypes != ‘object’]</div><div>numerical_cols</div></div><div><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/CE26E478-13F7-4935-AC5E-80F6B96DE0AB.png" height="211" width="549"/><br/></div><div><br/></div><div>使用(X-X’)/s公式计算标准分布，先计算平均值，标准差，再将numerical数据进行标准化处理：</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>numerical_col_means = df_dummy.loc[:,numerical_cols].mean()</div><div>numerical_col_std = df_dummy.loc[:,numerical_cols].std()</div><div>df_dummy.loc[:,numerical_cols] = (df_dummy.loc[:,numerical_cols] - numerical_col_means)/numerical_col_std</div><div><br/></div><div>df_dummy.head()</div></div><div><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/3146216D-F4B2-4C79-AD56-C6F1EB92EAE0.png" height="227" width="540"/><br/></div><div><br/></div><div>以上就完成了对数据的处理。</div><div>记下来要建立模型。</div><div><br/></div><div>首先需要将数据集分为训练集和测试集：</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>df_train_dummy = df_dummy.loc[df_train.index]</div><div>df_test_dummy = df_dummy.loc[df_test.index]</div></div><div><br/></div><div><br/></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>X_train = df_train_dummy.values</div><div>X_test = df_test_dummy.values</div></div><div><br/></div><div>在这里选择使用xgboost进行模型训练</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>from xgboost import XGBRegressor</div><div><div><br/></div><div><br/></div></div><div>params =[1,2,3,4,5,6]</div><div>test_scores = []</div><div>for param in params:</div><div>    clf = XGBRegressor(max_depth=param)</div><div>    test_score = np.sqrt(-cross_val_score(clf,X_train,y_train,cv=10,scoring='neg_mean_squared_error'))</div><div>    test_scores.append(test_score.mean())</div><div>    </div><div>plt.plot(params,test_scores)</div><div>plt.title("max_depth vs CV Error")</div></div><div><br/></div><div><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/68915716-BE8E-45FC-841D-100AB7ED58FF.png" height="265" width="421"/><br/></div><div><br/></div><div>可以看到当max_depth=5时，CV Error效果达到了0.125。</div><div><br/></div><div><span style="font-weight: bold; font-size: 24px;">提交结果</span></div><div>将训练好的模型对数据进行训练</div><div> </div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>xgb = XGBRegressor(max_depth=5)</div><div>xgb.fit(X_train,y_train)</div><div>y_xgb = np.expm1(xgb.predict(X_test))</div><div>df_submission = pd.DataFrame(data={'Id': df_test.index,'SalePrice':y_xgb})</div></div><div><br/></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>df_submission.head()</div></div><div><img src="Kaggle%3A%20House%20Prices%3A%20Advanced%20Regression%20Techniques.resources/4490F312-B12D-4DEB-BAB6-84074DB1D2A0.png" height="176" width="183"/><br/></div><div><br/></div><div>输出的数据结果如图所示</div><div>将其存为.csv文件</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>df_submission.to_csv('submission_xgb.csv',index=False)</div></div><div><br/></div><div>提交到kaggle平台之后的Score是0.13524，排名大约50%左右。</div><div><br/></div><div><span style="font-weight: bold; font-size: 24px;">总结</span></div><div>    之前做过一个分类项目，Titanic项目，当时对于特征方面的处理并不好，并且不懂得选取较好的模型进行训练。</div><div>    这个项目是一个回归分析项目，这次没有对特征进行过多的处理，主要是在模型选取上参照了一些资料，尝试之后最终选取了xgboost，效果也比较好。</div><div>    自己本身在特征处理上面也需要更多的经验和积累。</div><div><br/></div></body></html>